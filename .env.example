# HippocampAI Configuration
# Copy this file to .env and configure your settings

# ==================== API Configuration ====================
API_PORT=8000

# ==================== Qdrant Vector Database ====================
QDRANT_URL=http://localhost:6333
QDRANT_PORT=6333
QDRANT_GRPC_PORT=6334
COLLECTION_FACTS=hippocampai_facts
COLLECTION_PREFS=hippocampai_prefs

# ==================== HNSW Index Tuning (Advanced) ====================
# Higher M = better recall, more memory
HNSW_M=48
# Higher ef_construction = better index quality, slower build
EF_CONSTRUCTION=256
# Higher ef_search = better recall, slower search
EF_SEARCH=128

# ==================== Embedding Model ====================
EMBED_MODEL=BAAI/bge-small-en-v1.5
EMBED_DIMENSION=384
EMBED_BATCH_SIZE=32
EMBED_QUANTIZED=false

# ==================== Reranker (Cross-Encoder) ====================
RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2
RERANK_CACHE_TTL=86400

# ==================== LLM Provider Configuration ====================
# Options: ollama, openai, anthropic, groq
LLM_PROVIDER=ollama
LLM_MODEL=qwen2.5:7b-instruct

# For Ollama (local, self-hosted)
LLM_BASE_URL=http://localhost:11434

# For OpenAI (cloud)
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-4o-mini
# OPENAI_API_KEY=sk-your-key-here

# For Groq (fast, cost-effective cloud inference)
# LLM_PROVIDER=groq
# LLM_MODEL=llama-3.3-70b-versatile
# GROQ_API_KEY=gsk_your-groq-api-key-here

# For Anthropic (cloud)
# LLM_PROVIDER=anthropic
# LLM_MODEL=claude-3-haiku-20240307
# ANTHROPIC_API_KEY=sk-ant-your-key-here

# Allow cloud providers (set to true if using OpenAI/Anthropic/Groq)
ALLOW_CLOUD=false

# ==================== Retrieval Parameters ====================
# Number of candidates from vector search
TOP_K_QDRANT=200
# Final number of results after reranking
TOP_K_FINAL=20
# Reciprocal rank fusion parameter
RRF_K=60

# ==================== Scoring Weights (must sum to ~1.0) ====================
WEIGHT_SIM=0.55
WEIGHT_RERANK=0.20
WEIGHT_RECENCY=0.15
WEIGHT_IMPORTANCE=0.10

# ==================== Importance Decay Half-Lives (days) ====================
HALF_LIFE_PREFS=90
HALF_LIFE_FACTS=30
HALF_LIFE_EVENTS=14

# ==================== Background Jobs & Scheduling ====================
ENABLE_SCHEDULER=true
# Decay importance daily at 2am
DECAY_CRON=0 2 * * *
# Consolidate memories weekly on Sunday at 3am
CONSOLIDATE_CRON=0 3 * * 0
# Create snapshots hourly
SNAPSHOT_CRON=0 * * * *

# Background Tasks
ENABLE_BACKGROUND_TASKS=true
AUTO_DEDUP_ENABLED=true
AUTO_CONSOLIDATION_ENABLED=false
DEDUP_INTERVAL_HOURS=24
CONSOLIDATION_INTERVAL_HOURS=168
EXPIRATION_INTERVAL_HOURS=1

# ==================== Redis Cache ====================
REDIS_PORT=6379

# ==================== Monitoring ====================
PROMETHEUS_ENABLED=true
PROMETHEUS_PORT=9090

# Grafana
GRAFANA_PORT=3000
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=changeme_in_production
GRAFANA_ROOT_URL=http://localhost:3000

# ==================== Security (Recommended for Production) ====================
# Enable these in production deployments
# ENABLE_AUTH=true
# JWT_SECRET=your_jwt_secret_here
# RATE_LIMIT_PER_MINUTE=60
